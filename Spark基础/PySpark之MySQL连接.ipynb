{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark之MySQL连接\n",
    "说明：使用Spark SQL读写数据库Spark SQL可以支持Parquet、JSON、Hive等数据源，并且可以通过JDBC连接外部数据源。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from findspark import init\n",
    "init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.191.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>read_mysql</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=read_mysql>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"read_mysql\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从MySQL中读入数据\n",
    "-　MySQL表中数据内容  \n",
    "![](./imgs/sql显示.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jbdcDF = spark.read.format(\"jdbc\")\\\n",
    "        .option(\"driver\", \"com.mysql.jdbc.Driver\")\\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/spark\")\\\n",
    "        .option(\"dbtable\", \"student\")\\\n",
    "        .option(\"user\", \"root\")\\\n",
    "        .option(\"password\", \"123456\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+---+\n",
      "| id| name|gender|age|\n",
      "+---+-----+------+---+\n",
      "|  1|wanyu|     F| 25|\n",
      "|  2|manyu|     M| 18|\n",
      "|  1|wanyu|     F| 25|\n",
      "|  1|wanyu|     F| 25|\n",
      "+---+-----+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jbdcDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向MySQL中写入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris = spark.read.csv(\"file://\" + os.getcwd() + \"/data/iris.csv\", header=True)\n",
    "iris.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写入数据库\n",
    "prop = {}\n",
    "prop['user'] = 'root'\n",
    "prop['password'] = '123456'\n",
    "prop['driver'] = \"com.mysql.jdbc.Driver\"\n",
    "iris.write.jdbc(\"jdbc:mysql://localhost:3306/spark\",'iris','append', prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 写入MySQL结果显示  \n",
    "![](./imgs/sql读入.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 易错点\n",
    "(1)Py4JJavaError: An error occurred while calling o92.load. : java.lang.Class......  \n",
    "解决方法：[pyspark对Mysql数据库进行读写](https://zhuanlan.zhihu.com/p/136777424)  \n",
    "\n",
    "(2)java.sql.SQLException: Access denied for user 'root@localhost'@'localhost'  \n",
    "解决方法：\n",
    "```python\n",
    "mysql> ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';\n",
    "mysql> FLUSH PRIVILEGES;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[厦门大学林子雨老师主讲《Spark编程基础（Python版）》](http://dblab.xmu.edu.cn/post/12157/#kejianxiazai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
