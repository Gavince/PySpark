{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL\n",
    "## DataFrame基本操作\n",
    "### CSV格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as fn\n",
    "\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.60.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=test>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Ankit', age=25),\n",
       " Row(name='Jalfaizy', age=22),\n",
       " Row(name='saurabh', age=20),\n",
       " Row(name='Bala', age=26)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建DataFrame\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "# 加入键值对，即为数据加入列名\n",
    "people =rdd.map(lambda x:Row(name=x[0], age=int(x[1])))  \n",
    "people.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name|age|\n",
      "+--------+---+\n",
      "|   Ankit| 25|\n",
      "|Jalfaizy| 22|\n",
      "| saurabh| 20|\n",
      "|    Bala| 26|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemapeople = spark.createDataFrame(people)\n",
    "schemapeople.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(name,StringType,true),StructField(age,LongType,true)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemapeople.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 读csv格式文件\n",
    "# df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"./data/iris.csv\")\n",
    "df = spark.read.csv(\"./data/iris.csv\", header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: string (nullable = true)\n",
      " |-- sepal_width: string (nullable = true)\n",
      " |-- petal_length: string (nullable = true)\n",
      " |-- petal_width: string (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()  # 打印数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列名\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总数据\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|\n",
      "+------------+-----------+------------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|\n",
      "|         4.9|        3.0|         1.4|        0.2|\n",
      "|         4.7|        3.2|         1.3|        0.2|\n",
      "|         4.6|        3.1|         1.5|        0.2|\n",
      "|         5.0|        3.6|         1.4|        0.2|\n",
      "+------------+-----------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 默认删除列\n",
    "df.drop(\"species\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  species|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|  count|               150|                150|               150|               150|      150|\n",
      "|   mean| 5.843333333333335|  3.057333333333334|3.7580000000000027| 1.199333333333334|     null|\n",
      "| stddev|0.8280661279778637|0.43586628493669793|1.7652982332594662|0.7622376689603467|     null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 描述信息\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      petal_length|\n",
      "+-------+------------------+\n",
      "|  count|               150|\n",
      "|   mean|3.7580000000000027|\n",
      "| stddev|1.7652982332594662|\n",
      "|    min|               1.0|\n",
      "|    max|               6.9|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.describe(*cols)\n",
    "df.describe([\"petal_length\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sepal_length='5.1', sepal_width='3.5', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.9', sepal_width='3.0', petal_length='1.4', petal_width='0.2', species='setosa')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取指定列数据 以ROW类型数据格式进行数据存储\n",
    "df.select(\"*\").collect()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|sepal_width|sepal_length|\n",
      "+-----------+------------+\n",
      "|        3.5|         5.1|\n",
      "|        3.0|         4.9|\n",
      "|        3.2|         4.7|\n",
      "|        3.1|         4.6|\n",
      "|        3.6|         5.0|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  选几列数据\n",
    "df.select([\"sepal_width\", \"sepal_length\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   species|\n",
      "+----------+\n",
      "| virginica|\n",
      "|versicolor|\n",
      "|    setosa|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 显著分析\n",
    "df.select([\"species\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------------+\n",
      "|   species|max(sepal_width)|variance(sepal_length)|\n",
      "+----------+----------------+----------------------+\n",
      "| virginica|             3.8|    0.4043428571428571|\n",
      "|versicolor|             3.4|    0.2664326530612246|\n",
      "|    setosa|             4.4|   0.12424897959183674|\n",
      "+----------+----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  常用聚合函数\n",
    "# avg(), count(), countDistinct(), first(), kurtosis(),\n",
    "# max(), mean(), min(), skewness(), stddev(), stddev_pop(),\n",
    "# stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance()\n",
    "\n",
    "# 注意：同一列数据只能够统计一次\n",
    "df.groupBy(\"species\").agg({\"sepal_length\":\"mean\", \"sepal_width\":\"max\" , \"sepal_length\":\"variance\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+----------------+--------------+\n",
      "|count(sepal_length)|  avg(sepal_width)|max(sepal_width)|count(species)|\n",
      "+-------------------+------------------+----------------+--------------+\n",
      "|                150|3.0573333333333337|             4.4|             3|\n",
      "+-------------------+------------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fn 同一列数据可以统计多次,列名不同,聚合类型相同\n",
    "df.agg(fn.count(\"sepal_length\"), fn.mean(\"sepal_width\"), fn.max(\"sepal_width\"), fn.countDistinct(\"species\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据集\n",
    "train, val = df.randomSplit([0.7, 0.3], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70%做训练集\n",
    "train.count()/df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   species|\n",
      "+----------+\n",
      "| virginica|\n",
      "|versicolor|\n",
      "|    setosa|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看样本分配情况\n",
    "train.select(\"species\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      species\n",
       "0   virginica\n",
       "1  versicolor\n",
       "2      setosa"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以转为pandass数据处理\n",
    "val.select(\"species\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|species|\n",
      "+-------+\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 做减法，进行比较\n",
    "val.select(\"species\").subtract(train.select(\"species\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采样数据集\n",
    "sample_data = df.sample(False, 0.1, 3)\n",
    "sample_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|species_sepal_width|2.0|2.2|2.3|2.4|2.5|2.6|2.7|2.8|2.9|3.0|3.1|3.2|3.3|3.4|3.5|3.6|3.7|3.8|3.9|4.0|4.1|4.2|4.4|\n",
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|          virginica|  0|  1|  0|  0|  4|  2|  4|  8|  2| 12|  4|  5|  3|  2|  0|  1|  0|  2|  0|  0|  0|  0|  0|\n",
      "|             setosa|  0|  0|  1|  0|  0|  0|  0|  0|  1|  6|  4|  5|  2|  9|  6|  3|  3|  4|  2|  1|  1|  1|  1|\n",
      "|         versicolor|  1|  2|  3|  3|  4|  3|  5|  6|  7|  8|  3|  3|  1|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "+-------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 透视表\n",
    "df.crosstab(\"species\", \"sepal_width\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  species|\n",
      "+---------+\n",
      "|virginica|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF,testDF = df.randomSplit([0.99,0.01])\n",
    "diff_in_train_test = trainDF.select('species').subtract(testDF.select('species')).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.select('species').subtract(testDF.select('species')).distinct().rdd.map(lambda x:[0]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json格式文件处理\n",
    "json文件会自动检测数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }',\n",
       " '{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonString = [\n",
    "\"\"\"{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }\"\"\",\n",
    "\"\"\"{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }\"\"\"\n",
    "]\n",
    "jsonString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }',\n",
       " '{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonRDD = sc.parallelize(jsonString)\n",
    "jsonRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-----+\n",
      "|   city|   id|  pop|state|\n",
      "+-------+-----+-----+-----+\n",
      "| AGAWAM|01001|15338|   MA|\n",
      "|CUSHMAN|01002|36963|   MA|\n",
      "+-------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF = spark.read.json(jsonRDD)\n",
    "jsonDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- pop: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.printSchema()  # 着重区别与csv的格式数据的读入格式类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------+\n",
      "|code|    name|provinceCode|\n",
      "+----+--------+------------+\n",
      "|1101|  市辖区|          11|\n",
      "|1201|  市辖区|          12|\n",
      "|1301|石家庄市|          13|\n",
      "|1302|  唐山市|          13|\n",
      "|1303|秦皇岛市|          13|\n",
      "+----+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF = spark.read.json(\"data/province.json\")\n",
    "jsonDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- provinceCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------+------------------+\n",
      "|summary|             code|    name|      provinceCode|\n",
      "+-------+-----------------+--------+------------------+\n",
      "|  count|              342|     342|               342|\n",
      "|   mean|4046.502923976608|    null| 40.35672514619883|\n",
      "| stddev|1492.861959917837|    null|14.898333817383897|\n",
      "|    min|             1101|七台河市|                11|\n",
      "|    max|             6590|  龙岩市|                65|\n",
      "+-------+-----------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------------+\n",
      "|code|      name|provinceCode|\n",
      "+----+----------+------------+\n",
      "|1501|呼和浩特市|          15|\n",
      "|1502|    包头市|          15|\n",
      "|1503|    乌海市|          15|\n",
      "|1504|    赤峰市|          15|\n",
      "+----+----------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.filter(jsonDF.code>1440).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }',\n",
       " '{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#　更改数据为指定的数据类型\n",
    "jsonString = [\n",
    "\"\"\"{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }\"\"\",\n",
    "\"\"\"{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }\"\"\"\n",
    "]\n",
    "\n",
    "jsonRDD = sc.parallelize(jsonString)\n",
    "jsonRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义结构类型\n",
    "#StructType：schema的整体结构，表示JSON的对象结构\n",
    "#XXXStype:指的是某一列的数据类型\n",
    "jsonSchema = StructType() \\\n",
    "  .add(\"id\", StringType(),True) \\\n",
    "  .add(\"city\", StringType()) \\\n",
    "  .add(\"pop\" , LongType()) \\\n",
    "  .add(\"state\",StringType())\n",
    "\n",
    "# jsonSchema = StructType() \\\n",
    "#   .add(\"id\", LongType(),True) \\\n",
    "#   .add(\"city\", StringType()) \\\n",
    "#   .add(\"pop\" , DoubleType()) \\\n",
    "#   .add(\"state\",StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-----+\n",
      "|   id|   city|  pop|state|\n",
      "+-----+-------+-----+-----+\n",
      "|01001| AGAWAM|15338|   MA|\n",
      "|01002|CUSHMAN|36963|   MA|\n",
      "+-----+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader = spark.read.schema(jsonSchema)\n",
    "reader.json(jsonRDD).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- pop: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 读取数据类型\n",
    "reader.json(jsonRDD).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "  (1, 144.5, 5.9, 33, 'M'),\n",
    "  (2, 167.2, 5.4, 45, 'M'),\n",
    "  (3, 124.1, 5.2, 23, 'F'),\n",
    "  (4, 144.5, 5.9, 33, 'M'),\n",
    "  (5, 133.2, 5.7, 54, 'F'),\n",
    "  (3, 124.1, 5.2, 23, 'F'),\n",
    "  (5, 129.2, 5.3, 42, 'M'),\n",
    "], ['id', 'weight', 'height', 'age', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去重,默认消除相同的行, id=3\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 删除无意义字段之外的其他其他字段的重复数据\n",
    "df3 = df.drop_duplicates(subset=[c for c in df.columns if c!=\"id\"])\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|id_count|distinct_id_count|\n",
      "+--------+-----------------+\n",
      "|       5|                4|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 聚合某些特定的值, alias重命名数据格式\n",
    "df3.agg(fn.count(\"id\").alias(\"id_count\"), fn.countDistinct(\"id\").alias(\"distinct_id_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+-------------+\n",
      "| id|weight|height|age|gender|       new_id|\n",
      "+---+------+------+---+------+-------------+\n",
      "|  5| 133.2|   5.7| 54|     F|  25769803776|\n",
      "|  1| 144.5|   5.9| 33|     M| 171798691840|\n",
      "|  2| 167.2|   5.4| 45|     M| 592705486848|\n",
      "|  3| 124.1|   5.2| 23|     F|1236950581248|\n",
      "|  5| 129.2|   5.3| 42|     M|1365799600128|\n",
      "+---+------+------+---+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 添加新的一列数据index索引值，随机没有重复的索引值\n",
    "df3.withColumn(\"new_id\", fn.monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = spark.createDataFrame([\n",
    "(1, 143.5, 5.6, 28,'M', 100000),\n",
    "(2, 167.2, 5.4, 45,'M', None),\n",
    "(3, None , 5.2, None, None, None),\n",
    "(4, 144.5, 5.9, 33, 'M', None),\n",
    "(5, 133.2, 5.7, 54, 'F', None),\n",
    "(6, 124.1, 5.2, None, 'F', None),\n",
    "(7, 129.2, 5.3, 42, 'M', 76000),],\n",
    " ['id', 'weight', 'height', 'age', 'gender', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 4), (4, 1), (5, 1), (6, 2), (7, 0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计每一行的缺失值情况,转为rdd数据格式后，执行transformation操作\n",
    "df_miss.rdd.map(lambda row:(row[\"id\"], sum(c==None for c in row))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|id_missing|    weight_missing|height_missing|       age_missing|    gender_missing|    income_missing|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|       0.0|0.1428571428571429|           0.0|0.2857142857142857|0.1428571428571429|0.7142857142857143|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 统计列缺失情况\n",
    "df_miss.agg(*[(1-(fn.count(c)/fn.count(\"*\"))).alias(c+\"_missing\") for c in df_miss.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       7|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"*\"表示统计所有的数据\n",
    "df_miss.agg(fn.count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  3|  null|   5.2|null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 删除缺失值严重的列\n",
    "df_miss1 = df_miss.select([c for c in df_miss.columns if c!=\"income\"])\n",
    "df_miss1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n",
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 143.5|   5.6| 28|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  7| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除缺存在值超过指定阈值的行数据\n",
    "(df_miss1.dropna(thresh=3).show(), df_miss1.dropna(thresh=5).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n",
      "+---+------+------+---+------+------+\n",
      "| id|weight|height|age|gender|income|\n",
      "+---+------+------+---+------+------+\n",
      "|  1| 143.5|   5.6| 28|     M|100000|\n",
      "|  2| 167.2|   5.4| 45|     M|  6868|\n",
      "|  3| 150.0|   5.2| 18|   sex|  6868|\n",
      "|  4| 144.5|   5.9| 33|     M|  6868|\n",
      "|  5| 133.2|   5.7| 54|     F|  6868|\n",
      "|  6| 124.1|   5.2| 18|     F|  6868|\n",
      "|  7| 129.2|   5.3| 42|     M| 76000|\n",
      "+---+------+------+---+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss.show(), df_miss.fillna({\"weight\":150, \"age\":18, \"gender\":\"sex\", \"income\":6868}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 40.4,\n",
       "  'height': 5.471428571428572,\n",
       "  'id': 4.0,\n",
       "  'weight': 140.28333333333333}]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - 'records' : list like\n",
    "# [{column -> value}, ... , {column -> value}]\n",
    "\n",
    "bb = df_miss1.agg(*[fn.mean(c).alias(c) for c in df_miss1.columns if c!=\"gender\"]).toPandas()\n",
    "bb.to_dict(\"recoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 40.4,\n",
       " 'gender': 'M',\n",
       " 'height': 5.471428571428572,\n",
       " 'id': 4.0,\n",
       " 'weight': 140.28333333333333}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_fill = df_miss1.agg(*[fn.mean(c).alias(c) for c in df_miss1.columns if c!=\"gender\"]).toPandas().to_dict(\"records\")[0]\n",
    "miss_fill[\"gender\"] = \"M\"\n",
    "miss_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+---+------+\n",
      "| id|            weight|height|age|gender|\n",
      "+---+------------------+------+---+------+\n",
      "|  1|             143.5|   5.6| 28|     M|\n",
      "|  2|             167.2|   5.4| 45|     M|\n",
      "|  3|140.28333333333333|   5.2| 40|     M|\n",
      "|  4|             144.5|   5.9| 33|     M|\n",
      "|  5|             133.2|   5.7| 54|     F|\n",
      "|  6|             124.1|   5.2| 40|     F|\n",
      "|  7|             129.2|   5.3| 42|     M|\n",
      "+---+------------------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用字典对指定列数据进行缺失值填补\n",
    "df_miss1.fillna(miss_fill).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值处理\n",
    "- 异常值：不属于正常的值 包含：缺失值，超过正常范围内的较大值或较小值分位数去极值\n",
    "- 中位数绝对偏差去极值\n",
    "- 正态分布去极值  \n",
    "\n",
    "上述三种操作的核心都是：通过原始数据设定一个正常的范围，超过此范围的就是一个异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = spark.createDataFrame([\n",
    "(1, 143.5, 5.3, 28),\n",
    "(2, 154.2, 5.5, 45),\n",
    "(3, 342.3, 5.1, 99),\n",
    "(4, 144.5, 5.5, 33),\n",
    "(5, 133.2, 5.4, 54),\n",
    "(6, 124.1, 5.1, 21),\n",
    "(7, 129.2, 5.3, 42),\n",
    "], ['id', 'weight', 'height', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+\n",
      "| id|weight|height|age|\n",
      "+---+------+------+---+\n",
      "|  1| 143.5|   5.3| 28|\n",
      "|  2| 154.2|   5.5| 45|\n",
      "|  3| 342.3|   5.1| 99|\n",
      "|  4| 144.5|   5.5| 33|\n",
      "|  5| 133.2|   5.4| 54|\n",
      "|  6| 124.1|   5.1| 21|\n",
      "|  7| 129.2|   5.3| 42|\n",
      "+---+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"weight\", \"height\", \"age\"]\n",
    "bounds = {}\n",
    "\n",
    "for col in cols:\n",
    "    # 0.25, 0.75 分位数\n",
    "    quantiles = df_outliers.approxQuantile(col, [0.25, 0.75], 0)\n",
    "    \n",
    "    # 极差\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    bounds[col] = [quantiles[0]-1.5*IQR, quantiles[1]+1.5*IQR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [-11.0, 93.0],\n",
       " 'height': [4.499999999999999, 6.1000000000000005],\n",
       " 'weight': [91.69999999999999, 191.7]}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-----+\n",
      "| id|weight_o|height_o|age_o|\n",
      "+---+--------+--------+-----+\n",
      "|  1|   false|   false|false|\n",
      "|  2|   false|   false|false|\n",
      "|  3|    true|   false| true|\n",
      "|  4|   false|   false|false|\n",
      "|  5|   false|   false|false|\n",
      "|  6|   false|   false|false|\n",
      "|  7|   false|   false|false|\n",
      "+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = df_outliers.select(*['id'] + [( (df_outliers[c] < bounds[c][0]) | (df_outliers[c] > bounds[c][1]) ).alias(c + '_o') for c in cols ])\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|weight|\n",
      "+---+------+\n",
      "|  1| 143.5|\n",
      "|  2| 154.2|\n",
      "|  3| 342.3|\n",
      "|  4| 144.5|\n",
      "|  5| 133.2|\n",
      "|  6| 124.1|\n",
      "|  7| 129.2|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.select(\"id\", \"weight\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------+--------+-----+\n",
      "| id|weight|height|age|weight_o|height_o|age_o|\n",
      "+---+------+------+---+--------+--------+-----+\n",
      "|  7| 129.2|   5.3| 42|   false|   false|false|\n",
      "|  6| 124.1|   5.1| 21|   false|   false|false|\n",
      "|  5| 133.2|   5.4| 54|   false|   false|false|\n",
      "|  1| 143.5|   5.3| 28|   false|   false|false|\n",
      "|  3| 342.3|   5.1| 99|    true|   false| true|\n",
      "|  2| 154.2|   5.5| 45|   false|   false|false|\n",
      "|  4| 144.5|   5.5| 33|   false|   false|false|\n",
      "+---+------+------+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers = df_outliers.join(outliers, on=\"id\")\n",
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|weight|\n",
      "+---+------+\n",
      "|  3| 342.3|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.filter(\"weight_o\").select(\"id\", \"weight\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|  3| 99|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.filter(\"age_o\").select(\"id\", \"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
