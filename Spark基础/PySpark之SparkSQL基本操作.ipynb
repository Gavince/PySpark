{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as fn\n",
    "import os\n",
    "\n",
    "\n",
    "# 创建SparkSession实现其对数据加载、转换、处理等功能\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "ROOT_PATH = \"file://\" + os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://gavin-X550JX.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=test>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparkSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame的优点：\n",
    "- DataFrame的推出，让Spark具备了处理大规模结构化数据的能力，不仅比原有的RDD转化方式更加简单易用，而且获得了更高的计算性能\n",
    "- Spark能够轻松实现从MySQL到DataFrame的转化，并且支持SQL查询  \n",
    "\n",
    "DataFrame和RDD的区别:  \n",
    "![](./imgs/dataframe.png)\n",
    "- RDD是分布式的<font color = \"red\">Java对象的集合</font>，但是，对象内部结构对于RDD而言却是不可知的\n",
    "- DataFrame是一种以RDD为基础的分布式数据集，提供了详细的结构信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD与DataFrame互相转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Ankit', age=25),\n",
       " Row(name='Jalfaizy', age=22),\n",
       " Row(name='saurabh', age=20),\n",
       " Row(name='Bala', age=26)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建DataFrame\n",
    "l = [('Ankit',25),('Jalfaizy',22),('saurabh',20),('Bala',26)]\n",
    "rdd = sc.parallelize(l)\n",
    "\n",
    "# 加入键值对，即为数据加入列名\n",
    "people =rdd.map(lambda x:Row(name = x[0], age = int(x[1])))  \n",
    "people.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用对象的集合，需要使用对象调用属性\n",
    "row = Row(name=\"Alice\", age=11)\n",
    "row.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|    name|age|\n",
      "+--------+---+\n",
      "|   Ankit| 25|\n",
      "|Jalfaizy| 22|\n",
      "| saurabh| 20|\n",
      "|    Bala| 26|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemapeople = spark.createDataFrame(people)\n",
    "schemapeople.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: bigint]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建临时表，使用SQL语句进行查询\n",
    "schemapeople.createOrReplaceTempView(\"person\")\n",
    "spark.sql(\"select * from person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schemapeople.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='Ankit', age=25),\n",
       " Row(name='Jalfaizy', age=22),\n",
       " Row(name='saurabh', age=20),\n",
       " Row(name='Bala', age=26)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DateFrame转换为RDD格式数据\n",
    "schemapeople.rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkSQL基本操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV格式文件处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 读csv格式文件\n",
    "# 方法一\n",
    "# df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"./data/iris.csv\")\n",
    "# 方法二：\n",
    "df = spark.read.csv(ROOT_PATH + \"/data/iris.csv\", header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: string (nullable = true)\n",
      " |-- sepal_width: string (nullable = true)\n",
      " |-- petal_length: string (nullable = true)\n",
      " |-- petal_width: string (nullable = true)\n",
      " |-- species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 打印模式信息\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列名\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 总数据\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------+\n",
      "|sepal_length|petal_length|petal_width|\n",
      "+------------+------------+-----------+\n",
      "|         5.1|         1.4|        0.2|\n",
      "|         4.9|         1.4|        0.2|\n",
      "|         4.7|         1.3|        0.2|\n",
      "|         4.6|         1.5|        0.2|\n",
      "|         5.0|         1.4|        0.2|\n",
      "+------------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 默认删除列，传入为可变参数\n",
    "df.drop(*[\"species\", \"sepal_width\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  species|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "|  count|               150|                150|               150|               150|      150|\n",
      "|   mean| 5.843333333333335|  3.057333333333334|3.7580000000000027| 1.199333333333334|     null|\n",
      "| stddev|0.8280661279778637|0.43586628493669793|1.7652982332594662|0.7622376689603467|     null|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   setosa|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|virginica|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 描述信息\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      petal_length|\n",
      "+-------+------------------+\n",
      "|  count|               150|\n",
      "|   mean|3.7580000000000027|\n",
      "| stddev|1.7652982332594662|\n",
      "|    min|               1.0|\n",
      "|    max|               6.9|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.describe(*cols)\n",
    "df.describe(\"petal_length\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(sepal_length='5.1', sepal_width='3.5', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.9', sepal_width='3.0', petal_length='1.4', petal_width='0.2', species='setosa'),\n",
       " Row(sepal_length='4.7', sepal_width='3.2', petal_length='1.3', petal_width='0.2', species='setosa')]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取指定列数据 以ROW类型数据格式进行数据存储\n",
    "df.select(\"*\").collect()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+\n",
      "|sepal_width|sepal_length|\n",
      "+-----------+------------+\n",
      "|        3.5|         5.1|\n",
      "|        3.0|         4.9|\n",
      "|        3.2|         4.7|\n",
      "|        3.1|         4.6|\n",
      "|        3.6|         5.0|\n",
      "+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  选几列数据\n",
    "df.select(*[\"sepal_width\", \"sepal_length\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   species|\n",
      "+----------+\n",
      "| virginica|\n",
      "|versicolor|\n",
      "|    setosa|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 显著分析\n",
    "df.select([\"species\"]).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------------+\n",
      "|   species|max(sepal_width)|variance(sepal_length)|\n",
      "+----------+----------------+----------------------+\n",
      "| virginica|             3.8|    0.4043428571428571|\n",
      "|versicolor|             3.4|    0.2664326530612246|\n",
      "|    setosa|             4.4|   0.12424897959183674|\n",
      "+----------+----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 常用聚合函数\n",
    "# avg(), count(), countDistinct(), first(), kurtosis(),\n",
    "# max(), mean(), min(), skewness(), stddev(), stddev_pop(),\n",
    "# stddev_samp(), sum(), sumDistinct(), var_pop(), var_samp() and variance()\n",
    "\n",
    "# 注意：同一列数据只能够统计一次\n",
    "df.groupBy(\"species\").agg({\"sepal_length\":\"mean\", \"sepal_width\":\"max\" , \"sepal_length\":\"variance\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+----------------+--------------+\n",
      "|sepal_length_count|  avg(sepal_width)|max(sepal_width)|count(species)|\n",
      "+------------------+------------------+----------------+--------------+\n",
      "|               150|3.0573333333333337|             4.4|             3|\n",
      "+------------------+------------------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fn 同一列数据可以统计多次,列名不同,聚合类型相同\n",
    "df.agg(fn.count(\"sepal_length\").alias(\"sepal_length_count\"), fn.mean(\"sepal_width\"), fn.max(\"sepal_width\"), fn.countDistinct(\"species\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据集\n",
    "train, val = df.randomSplit([0.7, 0.3], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266666666666667"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 70%做训练集\n",
    "train.count()/df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|   species|\n",
      "+----------+\n",
      "| virginica|\n",
      "|versicolor|\n",
      "|    setosa|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看样本分配情况\n",
    "train.select(\"species\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      species\n",
       "0   virginica\n",
       "1  versicolor\n",
       "2      setosa"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以转为pandas数据处理\n",
    "val.select(\"species\").distinct().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|species|\n",
      "+-------+\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 做减法，进行比较\n",
    "val.select(\"species\").subtract(train.select(\"species\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采样数据集\n",
    "sample_data = df.sample(False, fraction = 0.1, seed = 3)\n",
    "sample_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species_sepal_width</th>\n",
       "      <th>2.0</th>\n",
       "      <th>2.2</th>\n",
       "      <th>2.3</th>\n",
       "      <th>2.4</th>\n",
       "      <th>2.5</th>\n",
       "      <th>2.6</th>\n",
       "      <th>2.7</th>\n",
       "      <th>2.8</th>\n",
       "      <th>2.9</th>\n",
       "      <th>...</th>\n",
       "      <th>3.4</th>\n",
       "      <th>3.5</th>\n",
       "      <th>3.6</th>\n",
       "      <th>3.7</th>\n",
       "      <th>3.8</th>\n",
       "      <th>3.9</th>\n",
       "      <th>4.0</th>\n",
       "      <th>4.1</th>\n",
       "      <th>4.2</th>\n",
       "      <th>4.4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginica</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>versicolor</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  species_sepal_width  2.0  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9  ...  3.4  \\\n",
       "0           virginica    0    1    0    0    4    2    4    8    2  ...    2   \n",
       "1              setosa    0    0    1    0    0    0    0    0    1  ...    9   \n",
       "2          versicolor    1    2    3    3    4    3    5    6    7  ...    1   \n",
       "\n",
       "   3.5  3.6  3.7  3.8  3.9  4.0  4.1  4.2  4.4  \n",
       "0    0    1    0    2    0    0    0    0    0  \n",
       "1    6    3    3    4    2    1    1    1    1  \n",
       "2    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉表,共现频率\n",
    "df.crosstab(\"species\", \"sepal_width\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0]]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.select('species').subtract(testDF.select('species')).distinct().rdd.map(lambda x:[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|petal_length|\n",
      "+------------+\n",
      "|         1.6|\n",
      "|         1.6|\n",
      "|         1.6|\n",
      "|         1.9|\n",
      "|         3.3|\n",
      "+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用临时表进行简单的SQL查询\n",
    "trainDF.createOrReplaceTempView(\"train_table\")\n",
    "# 返回一个DateFrame\n",
    "spark.sql(\"select petal_length from train_table where petal_length > 1.5\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必须写入全路径, 加上file://\n",
    "# 方法一：\n",
    "# trainDF.write.json((ROOT_PATH + \"/data/trainDF.json\")\n",
    "# 方法二：\n",
    "trainDF.write.format(\"json\").save(ROOT_PATH + \"/data/trainDF.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Json格式文件处理\n",
    "Json文件会自动检测数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }',\n",
       " '{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonString = [\n",
    "\"\"\"{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }\"\"\",\n",
    "\"\"\"{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }\"\"\"\n",
    "]\n",
    "jsonString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }',\n",
       " '{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonRDD = sc.parallelize(jsonString)\n",
    "jsonRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+-----+\n",
      "|   city|   id|  pop|state|\n",
      "+-------+-----+-----+-----+\n",
      "| AGAWAM|01001|15338|   MA|\n",
      "|CUSHMAN|01002|36963|   MA|\n",
      "+-------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF = spark.read.json(jsonRDD)\n",
    "jsonDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- pop: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.printSchema()  # 着重区别与csv的格式数据的读入格式类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------------+\n",
      "|code|    name|provinceCode|\n",
      "+----+--------+------------+\n",
      "|1101|  市辖区|          11|\n",
      "|1201|  市辖区|          12|\n",
      "|1301|石家庄市|          13|\n",
      "|1302|  唐山市|          13|\n",
      "|1303|秦皇岛市|          13|\n",
      "+----+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF = spark.read.json(ROOT_PATH + \"/data/province.json\")\n",
    "jsonDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- provinceCode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------+------------------+\n",
      "|summary|             code|    name|      provinceCode|\n",
      "+-------+-----------------+--------+------------------+\n",
      "|  count|              342|     342|               342|\n",
      "|   mean|4046.502923976608|    null| 40.35672514619883|\n",
      "| stddev|1492.861959917837|    null|14.898333817383897|\n",
      "|    min|             1101|七台河市|                11|\n",
      "|    max|             6590|  龙岩市|                65|\n",
      "+-------+-----------------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------------+\n",
      "|code|      name|provinceCode|\n",
      "+----+----------+------------+\n",
      "|1501|呼和浩特市|          15|\n",
      "|1502|    包头市|          15|\n",
      "|1503|    乌海市|          15|\n",
      "|1504|    赤峰市|          15|\n",
      "+----+----------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonDF.filter(jsonDF.code>1440).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }',\n",
       " '{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更改数据为指定的数据类型\n",
    "jsonString = [\n",
    "\"\"\"{ \"id\" : \"01001\", \"city\" : \"AGAWAM\",  \"pop\" : 15338, \"state\" : \"MA\" }\"\"\",\n",
    "\"\"\"{ \"id\" : \"01002\", \"city\" : \"CUSHMAN\", \"pop\" : 36963, \"state\" : \"MA\" }\"\"\"\n",
    "]\n",
    "\n",
    "jsonRDD = sc.parallelize(jsonString)\n",
    "jsonRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义结构类型（方法一）\n",
    "#StructType：schema的整体结构，表示JSON的对象结构\n",
    "#XXXStype:指的是某一列的数据类型\n",
    "jsonSchema = StructType() \\\n",
    "  .add(\"id\", StringType(),True) \\\n",
    "  .add(\"city\", StringType()) \\\n",
    "  .add(\"pop\" , LongType()) \\\n",
    "  .add(\"state\",StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-----+\n",
      "|   id|   city|  pop|state|\n",
      "+-----+-------+-----+-----+\n",
      "|01001| AGAWAM|15338|   MA|\n",
      "|01002|CUSHMAN|36963|   MA|\n",
      "+-----+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader = spark.read.schema(jsonSchema)\n",
    "reader.json(jsonRDD).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- pop: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 读取数据类型\n",
    "reader.json(jsonRDD).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-----+\n",
      "|   id|   city|  pop|state|\n",
      "+-----+-------+-----+-----+\n",
      "|01001| AGAWAM|15338|   MA|\n",
      "|01002|CUSHMAN|36963|   MA|\n",
      "+-----+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 改变输入数据的类型（方法二）\n",
    "scheme = StructType([StructField(\"id\", StringType())\n",
    "                     , StructField(\"city\", StringType())\n",
    "                     , StructField(\"pop\", LongType())\n",
    "                     , StructField(\"state\", StringType())\n",
    "                    ]\n",
    "                   )\n",
    "data1 = spark.read.json(jsonRDD, schema=scheme)\n",
    "data1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- pop: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([\n",
    "    \n",
    "    (1, 144.5, 5.9, 33, 'M'),\n",
    "    (2, 167.2, 5.4, 45, 'M'),\n",
    "    (3, 124.1, 5.2, 23, 'F'),\n",
    "    (4, 144.5, 5.9, 33, 'M'),\n",
    "    (5, 133.2, 5.7, 54, 'F'),\n",
    "    (3, 124.1, 5.2, 23, 'F'),\n",
    "    (5, 129.2, 5.3, 42, 'M'),]\n",
    "    , ['id', 'weight', 'height', 'age', 'gender']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 去重,默认消除相同的行(行元素相同), id=3（全部）\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  1| 144.5|   5.9| 33|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  3| 124.1|   5.2| 23|     F|\n",
      "|  5| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 删除无意义字段之外的其他其他字段的重复数据(部分，即部分子字段内重值进行删除, 例如id=1和id=4)\n",
    "df3 = df.drop_duplicates(subset=[c for c in df.columns if c!=\"id\"])\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|id_count|distinct_id_count|\n",
      "+--------+-----------------+\n",
      "|       5|                4|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 聚合某些特定的值, alias重命名数据格式\n",
    "df3.agg(fn.count(\"id\").alias(\"id_count\"), fn.countDistinct(\"id\").alias(\"distinct_id_count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+------+-------------+\n",
      "| id|weight|height|age|gender|       new_id|\n",
      "+---+------+------+---+------+-------------+\n",
      "|  5| 133.2|   5.7| 54|     F|  25769803776|\n",
      "|  1| 144.5|   5.9| 33|     M| 171798691840|\n",
      "|  2| 167.2|   5.4| 45|     M| 592705486848|\n",
      "|  3| 124.1|   5.2| 23|     F|1236950581248|\n",
      "|  5| 129.2|   5.3| 42|     M|1365799600128|\n",
      "+---+------+------+---+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 添加新的一列数据index索引值，随机没有重复的索引值\n",
    "df3.withColumn(\"new_id\", fn.monotonically_increasing_id()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss = spark.createDataFrame([\n",
    "    (1, 143.5, 5.6, 28,'M', 100000),\n",
    "    (2, 167.2, 5.4, 45,'M', None),\n",
    "    (3, None , 5.2, None, None, None),\n",
    "    (4, 144.5, 5.9, 33, 'M', None),\n",
    "    (5, 133.2, 5.7, 54, 'F', None),\n",
    "    (6, 124.1, 5.2, None, 'F', None),\n",
    "    (7, 129.2, 5.3, 42, 'M', 76000),]\n",
    "    , ['id', 'weight', 'height', 'age', 'gender', 'income']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_miss.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (2, 1), (3, 4), (4, 1), (5, 1), (6, 2), (7, 0)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计每一行的缺失值情况,转为rdd数据格式后，执行transformation操作, sum只对True进行统计\n",
    "df_miss.rdd.map(lambda row:(row[\"id\"], sum(c==None for c in row))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|id_missing|    weight_missing|height_missing|       age_missing|    gender_missing|    income_missing|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "|       0.0|0.1428571428571429|           0.0|0.2857142857142857|0.1428571428571429|0.7142857142857143|\n",
      "+----------+------------------+--------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 统计列缺失情况\n",
    "df_miss.agg(*[(1-(fn.count(c)/fn.count(\"*\"))).alias(c+\"_missing\") for c in df_miss.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       7|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \"*\"表示统计所有的数据\n",
    "df_miss.agg(fn.count(\"*\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  3|  null|   5.2|null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 删除缺失值严重的列\n",
    "df_miss1 = df_miss.select([c for c in df_miss.columns if c!=\"income\"])\n",
    "df_miss1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+\n",
      "| id|weight|height| age|gender|\n",
      "+---+------+------+----+------+\n",
      "|  1| 143.5|   5.6|  28|     M|\n",
      "|  2| 167.2|   5.4|  45|     M|\n",
      "|  4| 144.5|   5.9|  33|     M|\n",
      "|  5| 133.2|   5.7|  54|     F|\n",
      "|  6| 124.1|   5.2|null|     F|\n",
      "|  7| 129.2|   5.3|  42|     M|\n",
      "+---+------+------+----+------+\n",
      "\n",
      "+---+------+------+---+------+\n",
      "| id|weight|height|age|gender|\n",
      "+---+------+------+---+------+\n",
      "|  1| 143.5|   5.6| 28|     M|\n",
      "|  2| 167.2|   5.4| 45|     M|\n",
      "|  4| 144.5|   5.9| 33|     M|\n",
      "|  5| 133.2|   5.7| 54|     F|\n",
      "|  7| 129.2|   5.3| 42|     M|\n",
      "+---+------+------+---+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 删除缺存在值超过指定阈值的行数据，只要有超过thresh\n",
    "(df_miss1.dropna(thresh=3).show(), df_miss1.dropna(thresh=5).show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+----+------+------+\n",
      "| id|weight|height| age|gender|income|\n",
      "+---+------+------+----+------+------+\n",
      "|  1| 143.5|   5.6|  28|     M|100000|\n",
      "|  2| 167.2|   5.4|  45|     M|  null|\n",
      "|  3|  null|   5.2|null|  null|  null|\n",
      "|  4| 144.5|   5.9|  33|     M|  null|\n",
      "|  5| 133.2|   5.7|  54|     F|  null|\n",
      "|  6| 124.1|   5.2|null|     F|  null|\n",
      "|  7| 129.2|   5.3|  42|     M| 76000|\n",
      "+---+------+------+----+------+------+\n",
      "\n",
      "+---+------+------+---+------+------+\n",
      "| id|weight|height|age|gender|income|\n",
      "+---+------+------+---+------+------+\n",
      "|  1| 143.5|   5.6| 28|     M|100000|\n",
      "|  2| 167.2|   5.4| 45|     M|  6868|\n",
      "|  3| 150.0|   5.2| 18|   sex|  6868|\n",
      "|  4| 144.5|   5.9| 33|     M|  6868|\n",
      "|  5| 133.2|   5.7| 54|     F|  6868|\n",
      "|  6| 124.1|   5.2| 18|     F|  6868|\n",
      "|  7| 129.2|   5.3| 42|     M| 76000|\n",
      "+---+------+------+---+------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定字段进行填充指定值\n",
    "df_miss.show(), df_miss.fillna({\"weight\":150, \"age\":18, \"gender\":\"sex\", \"income\":6868}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 4.0,\n",
       "  'weight': 140.28333333333333,\n",
       "  'height': 5.471428571428572,\n",
       "  'age': 40.4}]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用均值进行填补.\n",
    "# - 'records' : list like\n",
    "# [{column -> value}, ... , {column -> value}]\n",
    "\n",
    "bb = df_miss1.agg(*[fn.mean(c).alias(c) for c in df_miss1.columns if c!=\"gender\"]).toPandas()\n",
    "bb.to_dict(\"recoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 4.0,\n",
       " 'weight': 140.28333333333333,\n",
       " 'height': 5.471428571428572,\n",
       " 'age': 40.4,\n",
       " 'gender': 'M'}"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss_fill = df_miss1.agg(*[fn.mean(c).alias(c) for c in df_miss1.columns if c!=\"gender\"]).toPandas().to_dict(\"records\")[0]\n",
    "miss_fill[\"gender\"] = \"M\"\n",
    "miss_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+------+---+------+\n",
      "| id|            weight|height|age|gender|\n",
      "+---+------------------+------+---+------+\n",
      "|  1|             143.5|   5.6| 28|     M|\n",
      "|  2|             167.2|   5.4| 45|     M|\n",
      "|  3|140.28333333333333|   5.2| 40|     M|\n",
      "|  4|             144.5|   5.9| 33|     M|\n",
      "|  5|             133.2|   5.7| 54|     F|\n",
      "|  6|             124.1|   5.2| 40|     F|\n",
      "|  7|             129.2|   5.3| 42|     M|\n",
      "+---+------------------+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用字典对指定列数据进行缺失值填补\n",
    "df_miss1.fillna(miss_fill).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值处理\n",
    "- 异常值：不属于正常的值 包含：缺失值，超过正常范围内的较大值或较小值分位数去极值\n",
    "- 中位数绝对偏差去极值\n",
    "- 正态分布去极值  \n",
    "\n",
    "上述三种操作的核心都是：通过原始数据设定一个正常的范围，超过此范围的就是一个异常值\n",
    "\n",
    "**知识点**：四分位数(处理异常值)   \n",
    "![](./imgs/四分位点.gif)  \n",
    "一般，数据集中的最小值我们称之为下界，最大值称之为上界。  \n",
    "计算四分位数之前，第一步需要先求中位数M，  \n",
    "下四分位数Q1=数据集中所有数值由小到大排列后第25%的数字  \n",
    "上四分位数Q3=数据集中所有数值由小到大排列后第75%的数字  \n",
    "四分位数间距：$IQR = Q3 - Q1$  \n",
    "下界（Min）：$Q1 - 1.5*IQR$  \n",
    "上界(Max)：$Q3 + 1.5*IQR$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = spark.createDataFrame([\n",
    "    (1, 143.5, 5.3, 28),\n",
    "    (2, 154.2, 5.5, 45),\n",
    "    (3, 342.3, 5.1, 99),\n",
    "    (4, 144.5, 5.5, 33),\n",
    "    (5, 133.2, 5.4, 54),\n",
    "    (6, 124.1, 5.1, 21),\n",
    "    (7, 129.2, 5.3, 42),\n",
    "    ]\n",
    "    , ['id', 'weight', 'height', 'age']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+\n",
      "| id|weight|height|age|\n",
      "+---+------+------+---+\n",
      "|  1| 143.5|   5.3| 28|\n",
      "|  2| 154.2|   5.5| 45|\n",
      "|  3| 342.3|   5.1| 99|\n",
      "|  4| 144.5|   5.5| 33|\n",
      "|  5| 133.2|   5.4| 54|\n",
      "|  6| 124.1|   5.1| 21|\n",
      "|  7| 129.2|   5.3| 42|\n",
      "+---+------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算数值型数据的四分位数据点\n",
    "cols = [\"weight\", \"height\", \"age\"]\n",
    "bounds = {}\n",
    "\n",
    "for col in cols:\n",
    "    # 0.25, 0.75 分位数\n",
    "    quantiles = df_outliers.approxQuantile(col, [0.25, 0.75], 0)\n",
    "    \n",
    "    # 极差\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    bounds[col] = [quantiles[0] - 1.5*IQR, quantiles[1] + 1.5*IQR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': [91.69999999999999, 191.7],\n",
       " 'height': [4.499999999999999, 6.1000000000000005],\n",
       " 'age': [-11.0, 93.0]}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+-----+\n",
      "| id|weight_o|height_o|age_o|\n",
      "+---+--------+--------+-----+\n",
      "|  7|   false|   false|false|\n",
      "|  6|   false|   false|false|\n",
      "|  5|   false|   false|false|\n",
      "|  1|   false|   false|false|\n",
      "|  3|    true|   false| true|\n",
      "|  2|   false|   false|false|\n",
      "|  4|   false|   false|false|\n",
      "+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outliers = df_outliers.select(*['id'] + [((df_outliers[c] < bounds[c][0]) | (df_outliers[c] > bounds[c][1])).alias(c + '_o') for c in cols])\n",
    "outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|weight|\n",
      "+---+------+\n",
      "|  1| 143.5|\n",
      "|  2| 154.2|\n",
      "|  3| 342.3|\n",
      "|  4| 144.5|\n",
      "|  5| 133.2|\n",
      "|  6| 124.1|\n",
      "|  7| 129.2|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.select(\"id\", \"weight\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+---+--------+--------+-----+\n",
      "| id|weight|height|age|weight_o|height_o|age_o|\n",
      "+---+------+------+---+--------+--------+-----+\n",
      "|  7| 129.2|   5.3| 42|   false|   false|false|\n",
      "|  6| 124.1|   5.1| 21|   false|   false|false|\n",
      "|  5| 133.2|   5.4| 54|   false|   false|false|\n",
      "|  1| 143.5|   5.3| 28|   false|   false|false|\n",
      "|  3| 342.3|   5.1| 99|    true|   false| true|\n",
      "|  2| 154.2|   5.5| 45|   false|   false|false|\n",
      "|  4| 144.5|   5.5| 33|   false|   false|false|\n",
      "+---+------+------+---+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers = df_outliers.join(outliers, on=\"id\")\n",
    "df_outliers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|weight|\n",
      "+---+------+\n",
      "|  3| 342.3|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.filter(\"weight_o\").select(\"id\", \"weight\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|  3| 99|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_outliers.filter(\"age_o\").select(\"id\", \"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "[基于PYSPARK创建DATAFRAME的几种方法](https://www.freesion.com/article/6509378157/#DataFrame_160)  \n",
    "[四分位数间距_四分位数计算公式_四分位数函数](http://www.ab126.com/goju/9536.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
